{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bank_churn.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1h1TVqdiKRHDZMew9Rh-AqzLg8sNvw3Qd",
      "authorship_tag": "ABX9TyNkDy7JYmy8bHzEweqZKcLD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaoni11/Coursera_Capstone/blob/master/bank_churn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2epHsmdb-rqu"
      },
      "source": [
        "#!pip install pandas_profiling --upgrade\n",
        "#!pip install klib\n",
        "#!pip install sweetviz\n",
        "import sys\n",
        "#!{sys.executable} -m pip install -U pandas-profiling[notebook]\n",
        "#!jupyter nbextension enable --py widgetsnbextension"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK3Uc5YYFRS7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import klib\n",
        "import pandas_profiling\n",
        "from pandas_profiling import ProfileReport\n",
        "import sweetviz\n",
        "import sklearn\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from platform import python_version\n",
        "import sklearn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import graphviz\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import *\n",
        "from sklearn.metrics import *\n",
        "\n",
        "from sklearn import set_config \n",
        "from sklearn.utils import estimator_html_repr \n",
        "from IPython.core.display import display, HTML \n",
        "\n",
        "set_config(display='diagram')\n",
        "from platform import python_version\n",
        "\n",
        "%precision 2\n",
        "pd.set_option('max_columns',200)\n",
        "pd.set_option('display.precision',2)\n",
        "pd.set_option('display.float_format','{:,.2f}'.format)\n",
        "\n",
        "\n",
        "from sklearn import set_config \n",
        "from sklearn.utils import estimator_html_repr \n",
        "from IPython.core.display import display, HTML \n",
        "\n",
        "set_config(display='diagram')\n",
        "from platform import python_version\n",
        "\n",
        "%precision 2\n",
        "\n",
        "pd.options.display.max_rows = 100\n",
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.width = 120\n",
        "pd.options.display.float_format='{:,.2f}'.format\n",
        "pd.options.display.precision = 2\n",
        "\n",
        "np.set_printoptions(precision=2, linewidth=120, suppress=True, edgeitems=5)\n",
        "\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "StartBold = \"\\033[1m\"\n",
        "EndBold = \"\\033[0m\"\n",
        "\n",
        "print('python',python_version())\n",
        "print(np.__name__, np.__version__)\n",
        "print(pd.__name__, pd.__version__)\n",
        "print(klib.__name__, klib.__version__)\n",
        "#print(pp.__name__, pp.__version__)\n",
        "print(sklearn.__name__, sklearn.__version__)\n",
        "print(sweetviz.__name__, sweetviz.__version__)\n",
        "\n",
        "pd.set_option('max_columns',200)\n",
        "pd.set_option('display.precision',2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_km6u4xIE46D"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/data/BankChurners.csv', index_col=0).iloc[:, :-2]\n",
        "\n",
        "# Reset index IDs and drop old index values\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(df.info())\n",
        "display(df.sample(5).T)  # Transpose just for easier viewing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0eM8ulKGORR"
      },
      "source": [
        "klib.missingval_plot(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PZ9SgoNJU4y"
      },
      "source": [
        "df_c = klib.data_cleaning(df, convert_dtypes=False)\n",
        "print(df_c.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qfNF0OcJXnS"
      },
      "source": [
        "profile = ProfileReport(df, explorative=True)\n",
        "profile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meMMLjNOJnPh"
      },
      "source": [
        "profile.to_file(\"Sales_Analysis.html\")\n",
        "profile.to_file(\"Sales_Analysis.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJwW5BVFkeH7"
      },
      "source": [
        "# Replace the values in attrition_flag with binary values, 1 for attrited_customer\n",
        "df_c['attrition_flag'].replace({'Existing Customer':False, 'Attrited Customer':True}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22QmeIErm8QA"
      },
      "source": [
        "df_c.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMvxmGNpDJYF"
      },
      "source": [
        "def plot_silhouettes(data, clusters, metric='euclidean'):\n",
        "    \n",
        "    from matplotlib import cm\n",
        "    from sklearn.metrics import silhouette_samples\n",
        "\n",
        "    cluster_labels = np.unique(clusters)\n",
        "    n_clusters = cluster_labels.shape[0]\n",
        "    silhouette_vals = metrics.silhouette_samples(data, clusters, metric='euclidean')\n",
        "    c_ax_lower, c_ax_upper = 0, 0\n",
        "    cticks = []\n",
        "    for i, k in enumerate(cluster_labels):\n",
        "        c_silhouette_vals = silhouette_vals[clusters == k]\n",
        "        c_silhouette_vals.sort()\n",
        "        c_ax_upper += len(c_silhouette_vals)\n",
        "        color = cm.jet(float(i) / n_clusters)\n",
        "        plt.barh(range(c_ax_lower, c_ax_upper), c_silhouette_vals, height=1.0, \n",
        "                      edgecolor='none', color=color)\n",
        "\n",
        "        cticks.append((c_ax_lower + c_ax_upper) / 2)\n",
        "        c_ax_lower += len(c_silhouette_vals)\n",
        "    \n",
        "    silhouette_avg = np.mean(silhouette_vals)\n",
        "    plt.axvline(silhouette_avg, color=\"red\", linestyle=\"--\") \n",
        "\n",
        "    plt.yticks(cticks, cluster_labels)\n",
        "    plt.ylabel('Cluster')\n",
        "    plt.xlabel('Silhouette coefficient')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return\n",
        "\n",
        "def plot_dendrogram(model, **kwargs):\n",
        "    from scipy.cluster.hierarchy import dendrogram\n",
        "    # Create linkage matrix and then plot the dendrogram\n",
        "\n",
        "    # create the counts of samples under each node\n",
        "    counts = np.zeros(model.children_.shape[0])\n",
        "    n_samples = len(model.labels_)\n",
        "    for i, merge in enumerate(model.children_):\n",
        "        current_count = 0\n",
        "        for child_idx in merge:\n",
        "            if child_idx < n_samples:\n",
        "                current_count += 1  # leaf node\n",
        "            else:\n",
        "                current_count += counts[child_idx - n_samples]\n",
        "        counts[i] = current_count\n",
        "\n",
        "    linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
        "                                      counts]).astype(float)\n",
        "\n",
        "    # Plot the corresponding dendrogram\n",
        "    dendrogram(linkage_matrix, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LeFECkFpR4y"
      },
      "source": [
        "for i in df_c.columns: # Make a for loops\n",
        "    if df_c[i].dtype == 'object':\n",
        "      df_dummies = pd.get_dummies(df_c) \n",
        "\n",
        "\n",
        "\n",
        "df_c.card_category = pd.Categorical(\n",
        "    df_c.card_category,\n",
        "    ['Blue' , 'Silver' ,'Gold' , 'Platinum'],\n",
        "    ordered=True)\n",
        "df_c.income_category = pd.Categorical(\n",
        "    df_c.income_category,\n",
        "    ['Unknown' , 'Less than $40K', '$40K - $60K', '$60K - $80K' ,'$80K - $120K' , '$120K +'],\n",
        "    ordered=True)\n",
        "df_c.education_level = pd.Categorical(\n",
        "    df_c.education_level,\n",
        "    ['Unknown' , 'Uneducated', 'High School', 'College' ,'Graduate' , 'Post-Graduate', 'Doctorate'],\n",
        "    ordered=True)\n",
        "\n",
        "df_c.gender = pd.Categorical(df_c.gender)\n",
        "df_c.marital_status = pd.Categorical(df_c.marital_status)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS9762txmYHK"
      },
      "source": [
        "\n",
        "# Split data in to Features X and Target y\n",
        "y = df_c['attrition_flag']\n",
        "X = df_c.drop(['attrition_flag'], axis=1)\n",
        "print('X and y shapes:')\n",
        "print(X.shape,y.shape,'\\n')\n",
        "print('Target Ratio:')\n",
        "print(y.value_counts(normalize=True, dropna=False),'\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA4guTR2njJM"
      },
      "source": [
        "y.value_counts(normalize=True, dropna=False).plot.bar(title='attrited_customer distribution');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8y6QAD6pueb"
      },
      "source": [
        "y.value_counts(normalize=True, dropna=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z94vDTaCCoPc"
      },
      "source": [
        "X.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E15ws__lEh_6"
      },
      "source": [
        "features_numeric     = list(df_c[[\"customer_age\",\"dependent_count\",\"months_on_book\",\"total_relationship_count\",\"months_inactive_12_mon\",\n",
        "           \"contacts_count_12_mon\",\"credit_limit\",\"total_revolving_bal\",\"avg_open_to_buy\",\"total_amt_chng_q4_q1\",\n",
        "           \"total_trans_amt\",\"total_trans_ct\",\"total_ct_chng_q4_q1\",\"avg_utilization_ratio\"]])\n",
        "features_nominal     = ['gender','marital_status']\n",
        "features_nominal_ohe = ['is_Female', 'is_Male', 'is_Divorced', 'is_Married', 'is_Single','is_Unknown_Marital'] # OneHotEncoded\n",
        "features_ordinal     = ['education_level','income_category','card_category']\n",
        "features_names       = df_c.columns[:19].values\n",
        "features_names_enc   =  features_numeric + features_ordinal + features_nominal_ohe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn5Up1NhEzTk"
      },
      "source": [
        "#Scale & Transform\n",
        "\n",
        "numeric_transformer = StandardScaler()\n",
        "ordinal_transformer = OrdinalEncoder()\n",
        "nominal_transformer = OneHotEncoder()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, features_numeric),\n",
        "        ('ord', ordinal_transformer, features_ordinal),\n",
        "        ('nom', nominal_transformer, features_nominal),\n",
        "    ],\n",
        "    remainder='passthrough',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "X_ = preprocessor.fit_transform(X)\n",
        "X_enc = pd.DataFrame(X_, columns=features_names_enc, index=X.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kc1OxCME6KJ"
      },
      "source": [
        "corr = X_enc.join(y).corr() # Join with y to be included in correlations\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "hm = sns.heatmap(corr, annot=True, center=0, linecolor='lightgray', linewidths=.01, ax=ax,\n",
        "                 cmap=\"coolwarm\", fmt='.2g', square=True, cbar=False,\n",
        "                 mask=((abs(corr)<=.6) | mask))\n",
        "plt.title('Correlation Heatmap (r>abs(.6))', fontsize=24);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B2x-qIgM9Pw"
      },
      "source": [
        "#Feature Analysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4yRVEPQNNcI"
      },
      "source": [
        "clf = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', DecisionTreeClassifier())\n",
        "    ])\n",
        "\n",
        "clf.fit(X, y)\n",
        "\n",
        "print(\"model score: %.3f\" % clf.score(X, y))\n",
        "print(classification_report(y,clf.predict(X)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwKuDzhaNpTi"
      },
      "source": [
        "\n",
        "from sklearn.tree import export_graphviz, plot_tree\n",
        "\n",
        "s = export_graphviz(clf.named_steps.classifier,            \n",
        "                feature_names = features_names_enc, \n",
        "                class_names= ['attrited','existing'],\n",
        "                filled = True,\n",
        "                max_depth = 3\n",
        "               )\n",
        "graphviz.Source(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW8xRt1ZNv2b"
      },
      "source": [
        "pd.DataFrame(clf.named_steps.classifier.feature_importances_,\n",
        "             index=features_names_enc,\n",
        "             columns=['Importance']\n",
        "            ).sort_values('Importance',ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUcxfKobN286"
      },
      "source": [
        "#Cluster Analysis\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.decomposition import PCA,KernelPCA, TruncatedSVD\n",
        "\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL0bChGLN9XN"
      },
      "source": [
        "#Trying K-Means\n",
        "pl_kmeans = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('cluster', KMeans(n_clusters=2))\n",
        "    ])\n",
        "\n",
        "clusters = pl_kmeans.fit_predict(X)\n",
        "kmeans = pl_kmeans.named_steps.cluster\n",
        "\n",
        "print('completeness_score: {:.2f}'.format(completeness_score(y,clusters)))\n",
        "print('homogeneity_score:  {:.2f}'.format(homogeneity_score(y,clusters)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JilbSI7nOCgB"
      },
      "source": [
        "plot_silhouettes(pl_kmeans.transform(X),clusters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN1wJuVkOGYS"
      },
      "source": [
        "# Check the clusters assignment distributions\n",
        "clusters_df = pd.DataFrame(clusters, columns=[\"Cluster\"])['Cluster']\n",
        "clusters_df.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un6-4rCLOO-o"
      },
      "source": [
        "#Cluster assignment representation:\n",
        "\n",
        "sns.pairplot(\n",
        "    x_vars=['months_on_book','avg_open_to_buy','avg_utilization_ratio','total_trans_ct'],\n",
        "    y_vars=['customer_age','credit_limit','total_revolving_bal','total_trans_amt'],\n",
        "    hue='Cluster',\n",
        "    height=3,\n",
        "    data=X_enc.reset_index(drop=True).join(clusters_df)\n",
        "    );"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eIvvUo1OWUV"
      },
      "source": [
        "# Elbow-curve/SSD\n",
        "ssd = []\n",
        "range_n_clusters = range(2,15)\n",
        "for num_clusters in range_n_clusters:\n",
        "    pl_kmeans = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('cluster', KMeans(n_clusters=num_clusters))\n",
        "    ])\n",
        "    \n",
        "    pl_kmeans.fit(X)\n",
        "    kmeans = pl_kmeans.named_steps.cluster\n",
        "    ssd.append(kmeans.inertia_)\n",
        "    \n",
        "# plot the SSDs for each n_clusters\n",
        "plt.plot(ssd);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvbYcoiTOgTW"
      },
      "source": [
        "# Silhouette Analysis\n",
        "range_n_clusters = range(2,15)\n",
        "for num_clusters in range_n_clusters:\n",
        "    \n",
        "    # Initialise kmeans\n",
        "    pl_kmeans = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('cluster', KMeans(n_clusters=num_clusters))\n",
        "    ])\n",
        "    \n",
        "    pl_kmeans.fit(X)\n",
        "    kmeans = pl_kmeans.named_steps.cluster\n",
        "\n",
        "    cluster_labels = kmeans.labels_\n",
        "    \n",
        "    # Silhouette Score\n",
        "    silhouette_avg = silhouette_score(pl_kmeans.transform(X), cluster_labels)\n",
        "    print(\"For n_clusters={0}, the silhouette score is {1}\".format(num_clusters, silhouette_avg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KsvheaKOnfA"
      },
      "source": [
        "#Trying agglomerative Clustering\n",
        "pl_kmeans = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('cluster', AgglomerativeClustering(n_clusters=2))\n",
        "    ])\n",
        "\n",
        "clusters = pl_kmeans.fit_predict(X)\n",
        "kmeans = pl_kmeans.named_steps.cluster\n",
        "\n",
        "print('completeness_score: {:.2f}'.format(completeness_score(y,clusters)))\n",
        "print('homogeneity_score:  {:.2f}'.format(homogeneity_score(y,clusters)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UceAKLfmO1N0"
      },
      "source": [
        "plot_silhouettes(X_enc,clusters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6EiAmtAO6YA"
      },
      "source": [
        "\n",
        "# Check the clusters assignment distributions\n",
        "clusters_df = pd.DataFrame(clusters, columns=[\"Cluster\"])['Cluster']\n",
        "clusters_df.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwGTJPUIPCT7"
      },
      "source": [
        "sns.lmplot(x=\"total_trans_ct\", y=\"total_trans_amt\", hue=\"Cluster\",\n",
        "           data=X_enc.reset_index(drop=True).join(clusters_df));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuJBLZavPGE5"
      },
      "source": [
        "sns.pairplot(\n",
        "    x_vars=['months_on_book','avg_open_to_buy','avg_utilization_ratio','total_trans_ct'],\n",
        "    y_vars=['customer_age','credit_limit','total_revolving_bal','total_trans_amt'],\n",
        "    hue='Cluster',\n",
        "    height=3,\n",
        "    data=X_enc.reset_index(drop=True).join(clusters_df)\n",
        "    );"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RISjBJCDPM_P"
      },
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "# setting distance_threshold=0 ensures we compute the full tree.\n",
        "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
        "model = model.fit(X_enc)\n",
        "\n",
        "plt.subplots(figsize=(20,5))\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "# plot the top three levels of the dendrogram\n",
        "plot_dendrogram(model, truncate_mode='level', p=1)\n",
        "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQnsuMiGPVaI"
      },
      "source": [
        "#Applying KernelPCA\n",
        "\n",
        "_ = X_enc[['total_trans_amt','total_trans_ct','total_revolving_bal']]\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "#ax.scatter(xs, ys, zs, marker=m)\n",
        "ax.scatter(_.iloc[:,0],_.iloc[:,1],_.iloc[:,2],c=y, alpha=.6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blr7Ov1WP23r"
      },
      "source": [
        "_ = X_enc[['total_trans_amt','total_trans_ct','total_revolving_bal']]\n",
        "_ = PCA(3).fit_transform(_)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "#ax.scatter(xs, ys, zs, marker=m)\n",
        "ax.scatter(_[:,0],_[:,1],_[:,2],c=y, alpha=.6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6cYqHmmP6Om"
      },
      "source": [
        "_ = X_enc[['total_trans_amt','total_trans_ct','total_revolving_bal']]\n",
        "_ = KernelPCA(3, kernel='poly', degree=5).fit_transform(_)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(_[:,0],_[:,1],_[:,2],c=y, alpha=.6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIckjktpP-6N"
      },
      "source": [
        "\n",
        "_ = X_enc[['total_trans_amt','total_trans_ct','total_revolving_bal']]\n",
        "_ = KernelPCA(3, kernel='sigmoid').fit_transform(_)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(_[:,0],_[:,1],_[:,2],c=y, alpha=.6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaA-YBAOQDN8"
      },
      "source": [
        "\n",
        "_ = X_enc[['total_trans_amt','total_trans_ct','total_revolving_bal']]\n",
        "_ = KernelPCA(3, kernel='sigmoid').fit_transform(_)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(_[:,0],_[:,1],_[:,2],c=y, alpha=.6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9ptFc3MQHlB"
      },
      "source": [
        "\n",
        "_ = X_enc[['total_trans_amt','total_trans_ct','total_revolving_bal']]\n",
        "_ = KernelPCA(3, kernel='rbf', gamma=5).fit_transform(_)\n",
        "clst = KMeans(2).fit_predict(_)\n",
        "print('completeness_score: {:.2f}'.format(completeness_score(y,clst)))\n",
        "print('homogeneity_score:  {:.2f}'.format(homogeneity_score(y,clst)))\n",
        "#fig = plt.figure()\n",
        "#ax = fig.add_subplot(111, projection='3d')\n",
        "plt.scatter(_[:,0],_[:,1],c=y, alpha=.6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1y3vxNaQMZI"
      },
      "source": [
        "plt.scatter(_[:,0],_[:,1],c=clst, alpha=.6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLdqc__zQQzy"
      },
      "source": [
        "for i in np.arange(1,10,1):\n",
        "    _ = X_enc[['total_trans_amt','total_trans_ct','total_revolving_bal']]\n",
        "    _ = KernelPCA(3, kernel='rbf', gamma=i).fit_transform(_)\n",
        "    clst = KMeans(2).fit_predict(_)\n",
        "    print(i)\n",
        "    print('completeness_score: {:.2f}'.format(completeness_score(y,clst)))\n",
        "    print('homogeneity_score:  {:.2f}'.format(homogeneity_score(y,clst)))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZDycissQX5L"
      },
      "source": [
        "_ = X_enc[['total_trans_amt','total_trans_ct','total_revolving_bal']]\n",
        "_ = KernelPCA(3, kernel='poly', degree=5).fit_transform(_)\n",
        "clst = AgglomerativeClustering().fit_predict(_)\n",
        "print('completeness_score: {:.2f}'.format(completeness_score(y,clst)))\n",
        "print('homogeneity_score:  {:.2f}'.format(homogeneity_score(y,clst)))\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(_[:,0],_[:,1],_[:,2],c=clst, alpha=.6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owjsq-QyRBUl"
      },
      "source": [
        "_ = df_c[['total_trans_amt','total_trans_ct','total_revolving_bal']]\n",
        "_ = KernelPCA(2, kernel='poly').fit_transform(_)\n",
        "clst = AgglomerativeClustering(2).fit_predict(_)\n",
        "print('completeness_score: {:.2f}'.format(completeness_score(y,clst)))\n",
        "print('homogeneity_score:  {:.2f}'.format(homogeneity_score(y,clst)))\n",
        "plt.scatter(_[:,0],_[:,1],c=y, alpha=.6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGITYenFRGLv"
      },
      "source": [
        "plt.scatter(_[:,0],_[:,1],c=clst, alpha=.6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWXE11hpRPKy"
      },
      "source": [
        "_ = X_enc[['total_trans_amt','total_trans_ct','total_revolving_bal']]\n",
        "_ = KernelPCA(2, kernel='poly').fit_transform(_)\n",
        "clst = DBSCAN(metric='cosine').fit_predict(_)\n",
        "print('completeness_score: {:.2f}'.format(completeness_score(y,clst)))\n",
        "print('homogeneity_score:  {:.2f}'.format(homogeneity_score(y,clst)))\n",
        "plt.scatter(_[:,0],_[:,1],c=clst, alpha=.6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgsiAJ5nRUjG"
      },
      "source": [
        "_ = df_c[['total_trans_amt','total_trans_ct','total_revolving_bal']]\n",
        "_ = KernelPCA(3, kernel='poly').fit_transform(_)\n",
        "clst = AgglomerativeClustering(2).fit_predict(_)\n",
        "print('completeness_score: {:.2f}'.format(completeness_score(y,clst)))\n",
        "print('homogeneity_score:  {:.2f}'.format(homogeneity_score(y,clst)))\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "#ax.scatter(xs, ys, zs, marker=m)\n",
        "ax.scatter(_[:,0],_[:,1],_[:,2],c=y, alpha=.6);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESQqx_9RRbti"
      },
      "source": [
        "# Global Parameters\n",
        "\n",
        "random_state = 2021\n",
        "n_jobs = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9kLMevoRu1z"
      },
      "source": [
        "#Helper Function\n",
        "def get_GS_cv_results(gs):\n",
        "    '''\n",
        "        Extract Grid Seach Results\n",
        "        Author: Mourad Askar\n",
        "    '''\n",
        "    _cv_results_ = gs.cv_results_\n",
        "    _scorer_keys = gs.scorer_.keys()\n",
        "\n",
        "    df_gs_scores = pd.DataFrame()\n",
        "\n",
        "    for k in _cv_results_.keys():\n",
        "        if k.startswith('param_'):\n",
        "            param_key = ('param',k.split('_',1)[1])\n",
        "            param_values = _cv_results_[k]\n",
        "            df_gs_scores = pd.concat([df_gs_scores,pd.DataFrame({param_key:param_values})], axis=1)\n",
        "\n",
        "        elif k.startswith('mean_train') or k.startswith('mean_test'):\n",
        "            score_key = (k.split('_',2)[2],k.split('_',2)[1])\n",
        "            score_results = _cv_results_[k]\n",
        "            df_gs_scores = pd.concat([df_gs_scores,pd.DataFrame({score_key:score_results})], axis=1)\n",
        "\n",
        "    return df_gs_scores\n",
        "\n",
        "def display_grid_search_scores_grid(gs):\n",
        "    '''\n",
        "        Display Grid Search Scores Table\n",
        "        Author: Mourad Askar\n",
        "    '''\n",
        "    _cv_results_ = gs.cv_results_\n",
        "    _scorer_keys = gs.scorer_.keys()\n",
        "    _param_keys = list(_cv_results_['params'][0].keys())\n",
        "    df_gs_scores = get_GS_cv_results(gs)\n",
        "    \n",
        "    display(df_gs_scores)\n",
        "    \n",
        "\n",
        "def plot_grid_search_results(gs, plot_scoring='f1'):\n",
        "    '''\n",
        "        Plot Grid Search Train/Val Scores\n",
        "        Author: Mourad Askar\n",
        "    '''\n",
        "    _cv_results_ = gs.cv_results_\n",
        "    _scorer_keys = gs.scorer_.keys()\n",
        "\n",
        "    if(type(gs) == GridSearchCV):\n",
        "        model = gs.best_estimator_\n",
        "        if(type(model) == Pipeline):\n",
        "            model = gs.best_estimator_.named_steps.classifier\n",
        "    else:\n",
        "        model = gs\n",
        "    \n",
        "    print(f'{StartBold}Estimator:{EndBold}')\n",
        "    display(model)\n",
        "    print()\n",
        "    print(f'{StartBold}Best Result (Suggested):{EndBold}')\n",
        "    print(f'{StartBold}\\t{\"\":20} {\"train\":>6} {\"valdn\":>6}{EndBold}')\n",
        "    for _score in _scorer_keys:\n",
        "        print('\\t{2:>20} {0:>6.2f} {1:>6.2f}'.format(_cv_results_['mean_train_' + _score][gs.best_index_],\n",
        "                                             _cv_results_['mean_test_' + _score][gs.best_index_],\n",
        "                                             _score))\n",
        "    print()\n",
        "    print(f'{StartBold}Params:{EndBold}')\n",
        "    print('\\t{}'.format(gs.best_params_))\n",
        "    print()\n",
        "    \n",
        " \n",
        "    scoring_label = plot_scoring\n",
        "    not_negative = 1\n",
        "    if plot_scoring.startswith('neg_'):\n",
        "        scoring_label = plot_scoring[4:]\n",
        "        not_negative = -1\n",
        "    df = pd.DataFrame({\n",
        "        'params': _cv_results_['params'],\n",
        "        'mean_train_' + plot_scoring: _cv_results_['mean_train_' + plot_scoring] * not_negative,\n",
        "        'mean_test_' + plot_scoring: _cv_results_['mean_test_' + plot_scoring] * not_negative\n",
        "    })\n",
        "    fig, ax = plt.subplots()\n",
        "    df.plot('params',['mean_train_' + plot_scoring,'mean_test_' + plot_scoring], 'line', ax=ax)\n",
        "    ax.axvline(gs.best_index_,0,1, color='r', linestyle='--')\n",
        "    plt.grid(axis='both',c='lightgrey',ls=':')\n",
        "    plt.xticks(ticks=range(df.params.count()), labels=df.index)\n",
        "    plt.tick_params(axis='x', rotation=0)\n",
        "    plt.xlabel('params index')\n",
        "    plt.ylabel(scoring_label)\n",
        "    plt.legend(['train','valdn'])\n",
        "    plt.show()\n",
        "    \n",
        "    #_ = gs\n",
        "    #df_ = pd.DataFrame(_.cv_results_).filter(regex='(?:mean_test)|(?:params)')\n",
        "    #df_.insert(0,'classifier',_.best_estimator_.named_steps.classifier.__class__.__name__)\n",
        "    #d_result = {_.best_estimator_.named_steps.classifier:dict(df_.iloc[_.best_index_])}\n",
        "    #d_result\n",
        "    display_grid_search_scores_grid(gs)\n",
        "\n",
        "    if(\"beep\" in globals()): beep(True)\n",
        "        \n",
        "def score_classification_model(fitted_model, X, y_true, return_score=False):\n",
        "    '''\n",
        "        Print Classification Metrics\n",
        "        Author: Mourad Askar\n",
        "    '''\n",
        "    p = fitted_model.predict(X)\n",
        "    \n",
        "    accuracy = metrics.accuracy_score(y_true, p)\n",
        "    f1 = metrics.f1_score(y_true, p)\n",
        "    recall = metrics.recall_score(y_true, p)\n",
        "    precision = metrics.precision_score(y_true, p)\n",
        "    balanced_accuracy = metrics.balanced_accuracy_score(y_true, p)\n",
        "    roc = metrics.roc_auc_score(y_true, p)\n",
        "\n",
        "    print('\\taccuracy score:          {:>5.2f}'.format(accuracy))\n",
        "    print('\\tf1 score:                {:>5.2f}'.format(f1))\n",
        "    print('\\trecall score:            {:>5.2f}'.format(recall))\n",
        "    print('\\tprecision score:         {:>5.2f}'.format(precision))\n",
        "    print('\\tbalanced_accuracy score: {:>5.2f}'.format(balanced_accuracy))\n",
        "    print('\\troc_auc score:           {:>5.2f}'.format(roc))\n",
        "\n",
        "    #print(metrics.classification_report(y_true,p))\n",
        "    metrics.plot_confusion_matrix(fitted_model,X, y_true)\n",
        "    plt.show()\n",
        "          \n",
        "    #print(metrics.classification_report(y_true,p, sample_weight=compute_sample_weight('balanced',y_true)))\n",
        "    #metrics.plot_confusion_matrix(fitted_model,X, y_true, sample_weight=compute_sample_weight('balanced',y_true))\n",
        "\n",
        "    if((type(return_score) is str) or return_score):\n",
        "        if(type(fitted_model) == GridSearchCV):\n",
        "            model = fitted_model.best_estimator_\n",
        "            if(type(model) == Pipeline):\n",
        "                model = fitted_model.best_estimator_.named_steps.classifier\n",
        "        else:\n",
        "            model = fitted_model\n",
        "        key = str(model).replace('\\n','') + ( (' - ' + return_score) if type(return_score) == str else '')\n",
        "        results_dict = {key : {}}\n",
        "        results_dict[key]['Estimator'] = model.__class__.__name__\n",
        "        results_dict[key]['TAG'] = return_score if type(return_score) == str else '-'\n",
        "        results_dict[key]['Accuracy'] = accuracy\n",
        "        results_dict[key]['F1'] = f1\n",
        "        results_dict[key]['Recall'] = recall\n",
        "        results_dict[key]['Precision'] = precision\n",
        "        results_dict[key]['Balanced_Accuracy'] = balanced_accuracy\n",
        "        results_dict[key]['ROC_AUC'] = roc\n",
        "        return(results_dict)\n",
        "    \n",
        "def plot_coefficients(coef, feature_names, top_n=0):\n",
        "    '''\n",
        "        Plot Coefficents Magnitude\n",
        "        Author: Mourad Askar\n",
        "    '''\n",
        "    _ = pd.DataFrame({'features':feature_names,'coef':coef}).sort_values('coef',key=lambda x: abs(x),ascending=False)\n",
        "    if top_n > 0:\n",
        "        _ = _.iloc[:top_n,:]\n",
        "    n_features = _.shape[0]\n",
        "    #plt.subplots(figsize=(10,20))\n",
        "    plt.barh(range(n_features), _['coef'], align='center')\n",
        "    plt.yticks(np.arange(n_features), _['features'])\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Feature')\n",
        "    plt.ylim(n_features,-1)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GUhgjqfSIYp"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPh2XG8fSNA2"
      },
      "source": [
        "numeric_transformer = StandardScaler()\n",
        "nominal_transformer = OneHotEncoder()\n",
        "ordinal_transformer = OrdinalEncoder()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('numeric', numeric_transformer, features_numeric),\n",
        "        ('nominal', nominal_transformer, features_nominal),\n",
        "        ('ordinal', ordinal_transformer, features_ordinal),\n",
        "    ])\n",
        "\n",
        "clf = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', SGDClassifier())\n",
        "    ])\n",
        "\n",
        "display(clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL0nWbMXSRtY"
      },
      "source": [
        "# Common Grid Search Parameters that will be use across all models\n",
        "\n",
        "grid_search_defaults = {\n",
        "    'cv': 5,\n",
        "    'scoring': ['f1', 'recall', 'precision', 'balanced_accuracy', 'accuracy', 'roc_auc'],\n",
        "    'refit': 'f1',\n",
        "    'return_train_score': True,\n",
        "    'error_score': 0,\n",
        "    'verbose': 3,\n",
        "    'n_jobs': n_jobs,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "914glFlmSWTr"
      },
      "source": [
        "#Modeling\n",
        "# Dictionary to collect the scores from different models\n",
        "scores_TestSet = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfnF-RYTScPx"
      },
      "source": [
        "#SGD Classifier\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=101,test_size=0.3)\n",
        "cl_pl = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', SGDClassifier(loss='log',n_jobs=n_jobs,class_weight={1:2},random_state=random_state))\n",
        "    ]\n",
        ")\n",
        "\n",
        "params = {\n",
        "#    'classifier__class_weight': ['balanced',{1:2},{1:3},{1:4}],\n",
        "    'classifier__l1_ratio': [0,.25,.5,.75,1],\n",
        "    'classifier__alpha': np.logspace(-4,-1,5).round(5),\n",
        "#    'classifier__alpha': [.0006,.0007,.0008],\n",
        "}\n",
        "gs = GridSearchCV(cl_pl, params, **grid_search_defaults)\n",
        "gs.fit(X,y)\n",
        "\n",
        "print(f'\\n\\n{StartBold}Train_Set Tuning Results:{EndBold}')\n",
        "plot_grid_search_results(gs, grid_search_defaults['refit'])\n",
        "print(f'\\n\\n{StartBold}Test_Set Results:{EndBold}')\n",
        "results = score_classification_model(gs, X_test, y_test, True)\n",
        "scores_TestSet.update(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNsmBrCqSkKJ"
      },
      "source": [
        "# Decision Tree Classifier\n",
        "cl_pl = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', DecisionTreeClassifier(class_weight={1:2}, random_state=random_state))\n",
        "    ]\n",
        ")\n",
        "\n",
        "params = {\n",
        "#    'classifier__class_weight': ['balanced',{1:2},{1:3},{1:4}],\n",
        "    'classifier__max_depth': [6,7,8],\n",
        "    'classifier__min_samples_split': [0,.01,.02,.03],\n",
        "#    'classifier__max_features': [.1,.5,1.0],\n",
        "}\n",
        "gs = GridSearchCV(cl_pl,params, **grid_search_defaults)\n",
        "gs.fit(X,y)\n",
        "\n",
        "print(f'\\n\\n{StartBold}Train_Set Tuning Results:{EndBold}')\n",
        "plot_grid_search_results(gs, grid_search_defaults['refit'])\n",
        "\n",
        "print(f'\\n\\n{StartBold}Test_Set Results:{EndBold}')\n",
        "results = score_classification_model(gs, X_test, y_test, True)\n",
        "scores_TestSet.update(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-l5NdVYUhjB"
      },
      "source": [
        "#Randoem Forest Classifier\n",
        "\n",
        "cl_pl = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', RandomForestClassifier(class_weight={1:2},n_jobs=-1,random_state=random_state))\n",
        "    ]\n",
        ")\n",
        "\n",
        "params = {\n",
        "#    'classifier__class_weight': ['balanced','balanced_subsample',{1:2},{1:3},{1:4}],\n",
        "#    'classifier__n_estimators': [200,300,400,500],\n",
        "    'classifier__max_depth': [24], #[16,24,32],\n",
        "    'classifier__min_samples_split': [.01,.05,.1],\n",
        "    'classifier__max_features': [.1,.5,1.0],\n",
        "}\n",
        "gs = GridSearchCV(cl_pl,params, **grid_search_defaults)\n",
        "gs.fit(X,y)\n",
        "\n",
        "print(f'\\n\\n{StartBold}Train_Set Tuning Results:{EndBold}')\n",
        "plot_grid_search_results(gs, grid_search_defaults['refit'])\n",
        "\n",
        "print(f'\\n\\n{StartBold}Test_Set Results:{EndBold}')\n",
        "results = score_classification_model(gs, X_test, y_test, True)\n",
        "scores_TestSet.update(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GhSb_-oU0Iz"
      },
      "source": [
        "pd.DataFrame(gs.best_estimator_.named_steps.classifier.feature_importances_,\n",
        "             index=features_names_enc,\n",
        "             columns=['Importance']\n",
        "            ).sort_values('Importance',ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DlQD7JpVHbo"
      },
      "source": [
        "\n",
        "pd.DataFrame(scores_TestSet).T.drop(columns='TAG')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoRFao4fVLTU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}